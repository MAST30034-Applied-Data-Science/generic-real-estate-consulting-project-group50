{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from json import dump\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "postcode_url = 'https://www.worldpostalcodes.org/l1/en/au/australia/list/r1/list-of-postcodes-in-victoria'\n",
    "\n",
    "response = requests.request(\"GET\", postcode_url, headers=None, data=None)\n",
    "bs_object = BeautifulSoup(response.text, 'html.parser')\n",
    "table_tag = bs_object.find('table')\n",
    "tr_tags = table_tag.find_all('tr')[2:]\n",
    "\n",
    "all_postcode = []\n",
    "for tr_tag in tr_tags:\n",
    "    postcode = tr_tag.next.next.text\n",
    "    if postcode != '':\n",
    "        all_postcode.append(int(postcode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcode = 3000\n",
    "page = 1\n",
    "url = f\"https://www.domain.com.au/rent/?postcode={postcode}&page={page}\"\n",
    "\n",
    "payload={}\n",
    "headers = {\n",
    "    'user-agent': 'ozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload, timeout=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "\n",
    "## loop over all postcodes in Vic\n",
    "for postcode in all_postcode:\n",
    "    print(f'postcode: {postcode}')\n",
    "    page = 1\n",
    "\n",
    "    ## iterate all available pages\n",
    "    while True:\n",
    "        url = f\"https://www.domain.com.au/rent/?postcode={postcode}&page={page}\"\n",
    "\n",
    "        payload={}\n",
    "        headers = {\n",
    "        'user-agent': 'ozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36'\n",
    "        }\n",
    "\n",
    "        response = requests.request(\"GET\", url, headers=headers, data=payload, timeout=5)\n",
    "\n",
    "        ## parse the web content\n",
    "        bs_object = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        target_ul = bs_object.find('ul', attrs={'data-testid': \"results\"})\n",
    "        # if page is not found, terminate current loop \n",
    "        if target_ul is None:\n",
    "            print('page not found')\n",
    "            break\n",
    "\n",
    "        ## get property detail links\n",
    "        all_links = target_ul.find_all('a')\n",
    "        for links in all_links:\n",
    "            urls.append(links['href'])\n",
    "        \n",
    "        page += 1\n",
    "        if page % 10 == 0:\n",
    "            print(page)\n",
    "\n",
    "        # time.sleep(random.uniform(0, 2))\n",
    "## Save urls to disk\n",
    "\n",
    "with open('urls.pickle', 'wb') as f:\n",
    "    pickle.dump(urls, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urls NO. 5400\n",
      "Urls NO. 5500\n",
      "Urls NO. 5600\n",
      "Urls NO. 5700\n",
      "Urls NO. 5800\n",
      "Urls NO. 5900\n",
      "Urls NO. 6000\n",
      "Urls NO. 6100\n",
      "Urls NO. 6200\n",
      "Urls NO. 6300\n",
      "Urls NO. 6400\n",
      "Urls NO. 6500\n",
      "Urls NO. 6600\n",
      "Urls NO. 6700\n",
      "Urls NO. 6800\n",
      "Urls NO. 6900\n",
      "Urls NO. 7000\n",
      "Urls NO. 7100\n",
      "Urls NO. 7200\n",
      "Urls NO. 7300\n",
      "Urls NO. 7400\n",
      "Urls NO. 7500\n",
      "Urls NO. 7600\n",
      "Urls NO. 7700\n",
      "Urls NO. 7800\n",
      "Urls NO. 7900\n",
      "Urls NO. 8000\n",
      "Urls NO. 8100\n",
      "Urls NO. 8200\n",
      "Urls NO. 8300\n",
      "Urls NO. 8400\n",
      "Urls NO. 8500\n",
      "Urls NO. 8600\n",
      "Urls NO. 8700\n",
      "Urls NO. 8800\n",
      "Urls NO. 8900\n",
      "Urls NO. 9000\n",
      "Urls NO. 9100\n",
      "Urls NO. 9200\n",
      "Urls NO. 9300\n",
      "Urls NO. 9400\n",
      "Urls NO. 9500\n",
      "Urls NO. 9600\n",
      "Urls NO. 9700\n",
      "Urls NO. 9800\n",
      "Urls NO. 9900\n",
      "Urls NO. 10000\n",
      "Urls NO. 10100\n",
      "Urls NO. 10200\n",
      "Urls NO. 10300\n",
      "Urls NO. 10400\n",
      "Urls NO. 10500\n",
      "Urls NO. 10600\n",
      "Urls NO. 10700\n",
      "Urls NO. 10800\n",
      "Urls NO. 10900\n",
      "Urls NO. 11000\n",
      "Urls NO. 11100\n",
      "Urls NO. 11200\n",
      "Urls NO. 11300\n",
      "Urls NO. 11400\n",
      "Urls NO. 11500\n",
      "Urls NO. 11600\n",
      "Urls NO. 11700\n",
      "Urls NO. 11800\n",
      "Urls NO. 11900\n",
      "Urls NO. 12000\n",
      "Urls NO. 12100\n",
      "Urls NO. 12200\n",
      "Urls NO. 12300\n",
      "Urls NO. 12400\n",
      "Urls NO. 12500\n",
      "Urls NO. 12600\n",
      "Urls NO. 12700\n",
      "Urls NO. 12800\n",
      "Urls NO. 12900\n",
      "Urls NO. 13000\n",
      "Urls NO. 13100\n",
      "Urls NO. 13200\n",
      "Urls NO. 13300\n",
      "Urls NO. 13400\n",
      "Urls NO. 13500\n",
      "Urls NO. 13600\n",
      "Urls NO. 13700\n",
      "Urls NO. 13800\n",
      "Urls NO. 13900\n",
      "Urls NO. 14000\n",
      "Urls NO. 14100\n",
      "Urls NO. 14200\n",
      "Urls NO. 14300\n",
      "Urls NO. 14400\n",
      "Urls NO. 14500\n",
      "Urls NO. 14600\n",
      "Urls NO. 14700\n",
      "Urls NO. 14800\n",
      "Urls NO. 14900\n",
      "Urls NO. 15000\n",
      "Urls NO. 15100\n",
      "Urls NO. 15200\n",
      "Urls NO. 15300\n",
      "Urls NO. 15400\n",
      "Urls NO. 15500\n",
      "Urls NO. 15600\n"
     ]
    }
   ],
   "source": [
    "properties_dict = {}\n",
    "failed_urls = []\n",
    "\n",
    "## loop over all urls\n",
    "for i, url in enumerate(urls):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Urls NO. {i}\")\n",
    "    \n",
    "    ## get the property content\n",
    "    payload={}\n",
    "    headers = {\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload, timeout=10)\n",
    "    \n",
    "    bs_object = BeautifulSoup(response.text, 'html.parser')\n",
    "    ## get price info\n",
    "    price_tag = bs_object.find('div', attrs={'data-testid': \"listing-details__summary-title\"})\n",
    "    if price_tag is None:\n",
    "        failed_urls.append(url)\n",
    "        continue\n",
    "    else:\n",
    "        price_text = bs_object.find('div', attrs={'data-testid': \"listing-details__summary-title\"}).text\n",
    "    ## get address info\n",
    "    address_text = bs_object.find('h1', attrs={'class': 'css-164r41r'}).text\n",
    "    ## get beds, baths and parking info\n",
    "    property_features_tag = bs_object.find('div', attrs={'data-testid': \"property-features-wrapper\"})\n",
    "    try:\n",
    "        if len(list(property_features_tag.children)) > 0:\n",
    "            num_bedrooms_text = property_features_tag.next.next.text\n",
    "            num_bathrooms_text = property_features_tag.next.next_sibling.next.text\n",
    "            num_parking_text = property_features_tag.next.next_sibling.next_sibling.next.text\n",
    "        else:\n",
    "            num_bedrooms_text = \"\"\n",
    "            num_bathrooms_text = \"\"\n",
    "            num_parking_text = \"\"\n",
    "    except:\n",
    "        continue\n",
    "    ## get propery type\n",
    "    property_type_text = bs_object.find('div', attrs={'data-testid': \"listing-summary-property-type\"}).next.text\n",
    "    ## get propery features\n",
    "    property_tag = bs_object.find('ul', attrs={'class': 'css-4ewd2m'})\n",
    "    if property_tag is not None:\n",
    "        property_features = [child.text for child in property_tag.children]\n",
    "    else:\n",
    "        property_features = []\n",
    "\n",
    "    ## save to a dict\n",
    "    property_dict = dict()\n",
    "    property_dict['price'] = price_text\n",
    "    property_dict['address'] = address_text\n",
    "    property_dict['postcode'] = address_text[-4:]\n",
    "    property_dict['bedrooms'] = num_bedrooms_text\n",
    "    property_dict['baths'] = num_bathrooms_text\n",
    "    property_dict['parking'] = num_parking_text\n",
    "    property_dict['property_type'] = property_type_text\n",
    "    property_dict['property_features'] = property_features\n",
    "\n",
    "    properties_dict[url] = property_dict\n",
    "\n",
    "    # time.sleep(random.uniform(0, 0.3))\n",
    "\n",
    "## output to disk\n",
    "with open('properties_dict.json', 'w') as f:\n",
    "    json.dump(properties_dict, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('properties_dict.json', 'r') as f:\n",
    "    properties_dict_copy = json.load(f)\n",
    "\n",
    "## postprocess raw data\n",
    "for url, item in properties_dict_copy.items():\n",
    "    ## get price\n",
    "    price = re.findall(r'\\$(\\d*\\.?\\d{0,2})?', re.split('[/ ]', item['price'])[0])\n",
    "    if len(price) != 0 and price[0] != '':\n",
    "        price[0] = price[0].replace(',', '')\n",
    "        if price[0].endswith('pw') or price[0].endswith('/w'):     \n",
    "            item['price'] = float(price[0][:-2])\n",
    "        else:\n",
    "            item['price'] = float(price[0])\n",
    "    else:\n",
    "        item['price'] = ''\n",
    "    ## get bedrooms\n",
    "    bedrooms = re.findall(r'(\\d{1,2})', item['bedrooms'])\n",
    "    if len(bedrooms) != 0:\n",
    "        item['bedrooms'] = int(bedrooms[0])\n",
    "    else:\n",
    "        item['bedrooms'] = 0\n",
    "    ## get baths \n",
    "    baths = re.findall(r'(\\d{1,2})', item['baths'])\n",
    "    if len(baths) != 0:\n",
    "        item['baths'] = int(baths[0])\n",
    "    else:\n",
    "        item['baths'] = 0\n",
    "    ## get parking  \n",
    "    parking = re.findall(r'(\\d{1,2})', item['parking'])\n",
    "    if len(parking) != 0:\n",
    "        item['parking'] = int(parking[0])\n",
    "    else:\n",
    "        item['parking'] = 0\n",
    "\n",
    "## output to disk\n",
    "with open('properties_dict_processed.json', 'w') as f:\n",
    "    json.dump(properties_dict_copy, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e8444348901a7044753b9d9c6fdd635d3680578abdde989f9aa023de316f3db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
